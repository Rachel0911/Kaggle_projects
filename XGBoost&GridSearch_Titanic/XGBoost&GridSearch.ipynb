{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c5fca71a2092cc4660b8e0ff89f4bd93e245415f"
   },
   "source": [
    "## I just have learned about GBDT algorithm and Grid Search to find the best hyperparameters in GBDT classifier. Thus, I used Titanic dataset to do some exercise. The public score in kaggle leaderboard is 0.77990.  \n",
    "\n",
    "The link of raw dataset  https://www.kaggle.com/c/titanic/data. I also offer data as Titanic_train.csv and Titanic_test.csv\n",
    "\n",
    "\n",
    "This is the first try to use GBDT for classification. And I am not good at feature engineering. Please give good suggestions at any part. I will appreciate it.  \n",
    "\n",
    "\n",
    "\n",
    "Attributes description  \n",
    "PassengerId:  passenger's identification  \n",
    "Survived: target variable(not exist in test dataset), 0 = No, 1 = Yes  \n",
    "Pclass: ticket class, 1st = Upper, 2nd = Middle, 3rd = Lower  \n",
    "Name: passenger's name\n",
    "Sex: male or female  \n",
    "Age: passenger's age  \n",
    "SibSp: number of siblings / spouses aboard  \n",
    "Parch: number of parents / children aboard  \n",
    "Ticket: ticket number  \n",
    "Fare: passenger fare  \n",
    "Cabin: cabin number  \n",
    "Embarked: port of embarkation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# read train and test data\n",
    "train_df = pd.read_csv(\"Titanic_train.csv\")\n",
    "test_df = pd.read_csv(\"Titanic_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "4679efece517127309d41748269bc99cffaa9651"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "(418, 11)\n"
     ]
    }
   ],
   "source": [
    "# shape of train and test data\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "14a86bd9bc63d24237e4e9cc71e2b07fb3eec45f"
   },
   "source": [
    "Train dataset has one more column than test. It is the target called survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "4e8428606fa5f4898c8d7597b2a012ee359f408a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show summary of train_df\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "bb53b4776bf612511bd45c74152d709feed5adf7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check type of each column\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "d28a5e57c5590d325241ede9ea1d73e1a75b1e29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass          object\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert Pclass to object\n",
    "train_df.Pclass = train_df.Pclass.astype('str')\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "21341507beb169763f19f0d5cff62bd5f148c72b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        3\n",
       "Name        891\n",
       "Sex           2\n",
       "Ticket      681\n",
       "Cabin       147\n",
       "Embarked      3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check unique number of object columns\n",
    "cat_list = [\"Pclass\",\"Name\",\"Sex\",\"Ticket\",\"Cabin\",\"Embarked\"]\n",
    "train_df[cat_list].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "17958e516624fa46da0882c1d4dc1dde8f1ac285"
   },
   "source": [
    " There are 891 rows in train data. \"Name\" has 891 unique value and \"Ticket\" has 681 unique value. We could consider drop them since they are so various. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff03d5488a87eff5134984419adc05af6bc0c22b"
   },
   "source": [
    "I think the following is Feature Engineering. If I was wrong, please tell me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "22b0d33e698a11e0e9b7550e9535471412189e46"
   },
   "outputs": [],
   "source": [
    "# drop columns\n",
    "drop_cols = [\"Name\",\"Ticket\"]\n",
    "train_df.drop(drop_cols, axis=1, inplace=True)\n",
    "test_df.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "bdadeadc8333e0176af7acbaf8378a4aa41773e6"
   },
   "outputs": [],
   "source": [
    "# extract traget \n",
    "train_y = train_df.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "95b98403ed3d22757e8bb73d03b5c72b0ba04b6c"
   },
   "outputs": [],
   "source": [
    "# extract ID of test for submission file\n",
    "test_ID = test_df.PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "82443ea47d82a5c197414c3a3e3b8ba48fbf7c00"
   },
   "outputs": [],
   "source": [
    "# drop PassengerId\n",
    "train_X = train_df.drop([\"PassengerId\"], axis=1)\n",
    "test_X = test_df.drop([\"PassengerId\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "228422f03f204e59c6f5e2251b25dd63c21853d0"
   },
   "outputs": [],
   "source": [
    "# extract features for training\n",
    "train_X = train_X.drop([\"Survived\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5bbe88aa8ce343d06f635a4fd0878e7518f8f6fb"
   },
   "source": [
    "This part is dealing with missing values and encoding categorical columns in order to be used in XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "ac22665b36902c35546ace4219450e4cb0ffaeab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'Cabin', 'Embarked']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check columns with NaN\n",
    "cols_with_missing = [col for col in train_X.columns \n",
    "                                 if train_X[col].isnull().any()]\n",
    "cols_with_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb799d3bd35a0ed3aa2fda2fd6076d1657f5ec9e"
   },
   "source": [
    "Firstly, select which columns are numeric and which are categorical and then handling with them seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "260edc6a9eb4e9cef8ecbba535b71e440a2b10fc"
   },
   "outputs": [],
   "source": [
    "# two lists contain numerical columns' name and categorical columns' name\n",
    "num_cols = [\"Age\",\"SibSp\",\"Parch\",\"Fare\"]\n",
    "cat_cols = [\"Sex\",\"Cabin\",\"Embarked\",\"Pclass\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "ba9e025cc582e5651e194af2552c9ab29798270f"
   },
   "outputs": [],
   "source": [
    "# handling missing value in num_cols using impute\n",
    "num_imputer = SimpleImputer()\n",
    "train_X[num_cols] = num_imputer.fit_transform(train_X[num_cols])\n",
    "test_X[num_cols] = num_imputer.fit_transform(test_X[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "0226a4d5ad7e916ea66f1464066636f3dfce5f8c"
   },
   "outputs": [],
   "source": [
    "# handling categorical columns using number label\n",
    "for col in cat_cols:\n",
    "    cat = LabelEncoder()\n",
    "    cat.fit(list(train_X[col].values.astype('str')) + list(test_X[col].values.astype('str')))\n",
    "    train_X[col] = cat.transform(list(train_X[col].values.astype('str')))\n",
    "    test_X[col] = cat.transform(list(test_X[col].values.astype('str')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cbb60e508d895662fe67491dc947947174f71aef"
   },
   "source": [
    "After feature engineering, handling missing values and converting categorical values, I will use XGBoost algorithm to build model and predict for test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "c77c56e4ba3a97bc3ce3e01a6f232b2c75b3add4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'learning_rate': [0.06], 'n_estimators': [300], 'colsample_bytree': [0.7], 'reg_alpha': [0.04]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create XGBClassifier instance\n",
    "classifier = XGBClassifier()\n",
    "# set hypermeters and the below values are trained in order to run fast\n",
    "grid_param = {\"learning_rate\" : [0.06],\n",
    "              'n_estimators': [300],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'reg_alpha': [0.04]\n",
    "              }\n",
    "\n",
    "gd_sr = GridSearchCV(estimator=classifier,  \n",
    "                     param_grid=grid_param,\n",
    "                     scoring='accuracy',\n",
    "                     cv=10,\n",
    "                     n_jobs=-1,\n",
    "                    verbose=1)\n",
    "gd_sr.fit(train_X, train_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "b20b62f1f817ca73128b8efcacf88b6a602819e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.7, 'learning_rate': 0.06, 'n_estimators': 300, 'reg_alpha': 0.04}\n"
     ]
    }
   ],
   "source": [
    "# print the best hyparameters, but for my case, the best parameters are shown as above\n",
    "# I used this to find the best hyperparameters from lots of hyparameters combination\n",
    "best_parameters = gd_sr.best_params_  \n",
    "print(best_parameters)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "3715a0b3973dd6d4cd843f6554ae6c2711fecf64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Accuracy: 89.45%\n"
     ]
    }
   ],
   "source": [
    "train_pred = gd_sr.predict(train_X)\n",
    "pred_train = [round(value) for value in train_pred]\n",
    "# evaluate predictions\n",
    "acc_train = accuracy_score(train_y, pred_train)\n",
    "print(\"Train_Accuracy: %.2f%%\" % (acc_train * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "b34e30fe56aaba1e1ca40adf44c125175523a8ae"
   },
   "outputs": [],
   "source": [
    "# predict test dataset\n",
    "predictions = gd_sr.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "da3d3790c2ba3247f5717cae09f87dad14306ca3"
   },
   "outputs": [],
   "source": [
    "# satisfy submission format\n",
    "my_submission = pd.DataFrame({'PassengerId':test_ID,'Survived':predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "9f3b38f4e297e240c5b23b1ebfa20a4b57359298"
   },
   "outputs": [],
   "source": [
    "# export as csv file\n",
    "my_submission.to_csv(\"sub.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
