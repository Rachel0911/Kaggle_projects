{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c5fca71a2092cc4660b8e0ff89f4bd93e245415f"
   },
   "source": [
    "## I just have learned about XGBoost algorithm and Grid Search to find the best hyperparameters in XGBoost classifier. Thus, I used Titanic dataset to do some exercise. The public score in kaggle leaderboard is 0.77990.  \n",
    "\n",
    "The link of dataset  https://www.kaggle.com/c/titanic/data \n",
    "\n",
    "\n",
    "This is the first try to use XGBoost for classification. And I am not good at feature engineering. Please give good suggestions at any part. I will appreciate it.  \n",
    "\n",
    "\n",
    "\n",
    "Attributes description  \n",
    "PassengerId:  passenger's identification  \n",
    "Survived: target variable(not exist in test dataset), 0 = No, 1 = Yes  \n",
    "Pclass: ticket class, 1st = Upper, 2nd = Middle, 3rd = Lower  \n",
    "Name: passenger's name\n",
    "Sex: male or female  \n",
    "Age: passenger's age  \n",
    "SibSp: number of siblings / spouses aboard  \n",
    "Parch: number of parents / children aboard  \n",
    "Ticket: ticket number  \n",
    "Fare: passenger fare  \n",
    "Cabin: cabin number  \n",
    "Embarked: port of embarkation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# read train and test data\n",
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4679efece517127309d41748269bc99cffaa9651"
   },
   "outputs": [],
   "source": [
    "# shape of train and test data\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "14a86bd9bc63d24237e4e9cc71e2b07fb3eec45f"
   },
   "source": [
    "Train dataset has one more column than test. It is the target called survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e8428606fa5f4898c8d7597b2a012ee359f408a"
   },
   "outputs": [],
   "source": [
    "# show summary of train_df\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bb53b4776bf612511bd45c74152d709feed5adf7"
   },
   "outputs": [],
   "source": [
    "# check type of each column\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d28a5e57c5590d325241ede9ea1d73e1a75b1e29"
   },
   "outputs": [],
   "source": [
    "# convert Pclass to object\n",
    "train_df.Pclass = train_df.Pclass.astype('str')\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "21341507beb169763f19f0d5cff62bd5f148c72b"
   },
   "outputs": [],
   "source": [
    "# check unique number of object columns\n",
    "cat_list = [\"Pclass\",\"Name\",\"Sex\",\"Ticket\",\"Cabin\",\"Embarked\"]\n",
    "train_df[cat_list].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "17958e516624fa46da0882c1d4dc1dde8f1ac285"
   },
   "source": [
    " There are 891 rows in train data. \"Name\" has 891 unique value and \"Ticket\" has 681 unique value. We could consider drop them since they are so various. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff03d5488a87eff5134984419adc05af6bc0c22b"
   },
   "source": [
    "I think the following is Feature Engineering. If I was wrong, please tell me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "22b0d33e698a11e0e9b7550e9535471412189e46"
   },
   "outputs": [],
   "source": [
    "# drop columns\n",
    "drop_cols = [\"Name\",\"Ticket\"]\n",
    "train_df.drop(drop_cols, axis=1, inplace=True)\n",
    "test_df.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bdadeadc8333e0176af7acbaf8378a4aa41773e6"
   },
   "outputs": [],
   "source": [
    "# extract traget \n",
    "train_y = train_df.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "95b98403ed3d22757e8bb73d03b5c72b0ba04b6c"
   },
   "outputs": [],
   "source": [
    "# extract ID of test for submission file\n",
    "test_ID = test_df.PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82443ea47d82a5c197414c3a3e3b8ba48fbf7c00"
   },
   "outputs": [],
   "source": [
    "# drop PassengerId\n",
    "train_X = train_df.drop([\"PassengerId\"], axis=1)\n",
    "test_X = test_df.drop([\"PassengerId\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "228422f03f204e59c6f5e2251b25dd63c21853d0"
   },
   "outputs": [],
   "source": [
    "# extract features for training\n",
    "train_X = train_X.drop([\"Survived\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5bbe88aa8ce343d06f635a4fd0878e7518f8f6fb"
   },
   "source": [
    "This part is dealing with missing values and encoding categorical columns in order to be used in XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ac22665b36902c35546ace4219450e4cb0ffaeab"
   },
   "outputs": [],
   "source": [
    "# check columns with NaN\n",
    "cols_with_missing = [col for col in train_X.columns \n",
    "                                 if train_X[col].isnull().any()]\n",
    "cols_with_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb799d3bd35a0ed3aa2fda2fd6076d1657f5ec9e"
   },
   "source": [
    "Firstly, select which columns are numeric and which are categorical and then handling with them seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "260edc6a9eb4e9cef8ecbba535b71e440a2b10fc"
   },
   "outputs": [],
   "source": [
    "# two lists contain numerical columns' name and categorical columns' name\n",
    "num_cols = [\"Age\",\"SibSp\",\"Parch\",\"Fare\"]\n",
    "cat_cols = [\"Sex\",\"Cabin\",\"Embarked\",\"Pclass\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ba9e025cc582e5651e194af2552c9ab29798270f"
   },
   "outputs": [],
   "source": [
    "# handling missing value in num_cols using impute\n",
    "num_imputer = SimpleImputer()\n",
    "train_X[num_cols] = num_imputer.fit_transform(train_X[num_cols])\n",
    "test_X[num_cols] = num_imputer.fit_transform(test_X[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0226a4d5ad7e916ea66f1464066636f3dfce5f8c"
   },
   "outputs": [],
   "source": [
    "# handling categorical columns using number label\n",
    "for col in cat_cols:\n",
    "    cat = LabelEncoder()\n",
    "    cat.fit(list(train_X[col].values.astype('str')) + list(test_X[col].values.astype('str')))\n",
    "    train_X[col] = cat.transform(list(train_X[col].values.astype('str')))\n",
    "    test_X[col] = cat.transform(list(test_X[col].values.astype('str')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cbb60e508d895662fe67491dc947947174f71aef"
   },
   "source": [
    "After feature engineering, handling missing values and converting categorical values, I will use XGBoost algorithm to build model and predict for test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c77c56e4ba3a97bc3ce3e01a6f232b2c75b3add4"
   },
   "outputs": [],
   "source": [
    "# create XGBClassifier instance\n",
    "classifier = XGBClassifier()\n",
    "# set hypermeters and the below values are trained in order to run fast\n",
    "grid_param = {\"learning_rate\" : [0.06],\n",
    "              'n_estimators': [300],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'reg_alpha': [0.04]\n",
    "              }\n",
    "\n",
    "gd_sr = GridSearchCV(estimator=classifier,  \n",
    "                     param_grid=grid_param,\n",
    "                     scoring='accuracy',\n",
    "                     cv=10,\n",
    "                     n_jobs=-1,\n",
    "                    verbose=1)\n",
    "gd_sr.fit(train_X, train_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b20b62f1f817ca73128b8efcacf88b6a602819e8"
   },
   "outputs": [],
   "source": [
    "# print the best hyparameters, but for my case, the best parameters are shown as above\n",
    "# I used this to find the best hyperparameters from lots of hyparameters combination\n",
    "best_parameters = gd_sr.best_params_  \n",
    "print(best_parameters)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3715a0b3973dd6d4cd843f6554ae6c2711fecf64"
   },
   "outputs": [],
   "source": [
    "train_pred = gd_sr.predict(train_X)\n",
    "pred_train = [round(value) for value in train_pred]\n",
    "# evaluate predictions\n",
    "acc_train = accuracy_score(train_y, pred_train)\n",
    "print(\"Train_Accuracy: %.2f%%\" % (acc_train * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b34e30fe56aaba1e1ca40adf44c125175523a8ae"
   },
   "outputs": [],
   "source": [
    "# predict test dataset\n",
    "predictions = gd_sr.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da3d3790c2ba3247f5717cae09f87dad14306ca3"
   },
   "outputs": [],
   "source": [
    "# satisfy submission format\n",
    "my_submission = pd.DataFrame({'PassengerId':test_ID,'Survived':predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f3b38f4e297e240c5b23b1ebfa20a4b57359298"
   },
   "outputs": [],
   "source": [
    "# export as csv file\n",
    "my_submission.to_csv(\"sub.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "891cebd2d83a66611d59871bea279b108e605d93"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
