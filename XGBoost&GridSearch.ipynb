{
  "cells": [
    {
      "metadata": {
        "_uuid": "c5fca71a2092cc4660b8e0ff89f4bd93e245415f"
      },
      "cell_type": "markdown",
      "source": "## I just have learned about XGBoost algorithm and Grid Search to find the best hyperparameters in XGBoost classifier. Thus, I used Titanic dataset to do some exercise.   \n\nThe link of dataset  https://www.kaggle.com/c/titanic/data \n\n\nThis is the first try to use XGBoost for classification. And I am not good at feature engineering. Please give good suggestions at any part. I will appreciate it.  \n\n\n\nAttributes description  \nPassengerId:  passenger's identification  \nSurvived: target variable(not exist in test dataset), 0 = No, 1 = Yes  \nPclass: ticket class, 1st = Upper, 2nd = Middle, 3rd = Lower  \nName: passenger's name\nSex: male or female  \nAge: passenger's age  \nSibSp: number of siblings / spouses aboard  \nParch: number of parents / children aboard  \nTicket: ticket number  \nFare: passenger fare  \nCabin: cabin number  \nEmbarked: port of embarkation"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# import required libraries\nimport numpy as np \nimport pandas as pd \nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# read train and test data\ntrain_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4679efece517127309d41748269bc99cffaa9651"
      },
      "cell_type": "code",
      "source": "# shape of train and test data\nprint(train_df.shape)\nprint(test_df.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "14a86bd9bc63d24237e4e9cc71e2b07fb3eec45f"
      },
      "cell_type": "markdown",
      "source": "Train dataset has one more column than test. It is the target called survived"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4e8428606fa5f4898c8d7597b2a012ee359f408a"
      },
      "cell_type": "code",
      "source": "# show summary of train_df\ntrain_df.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bb53b4776bf612511bd45c74152d709feed5adf7"
      },
      "cell_type": "code",
      "source": "# check type of each column\ntrain_df.dtypes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d28a5e57c5590d325241ede9ea1d73e1a75b1e29"
      },
      "cell_type": "code",
      "source": "# convert Pclass to object\ntrain_df.Pclass = train_df.Pclass.astype('str')\ntrain_df.dtypes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "21341507beb169763f19f0d5cff62bd5f148c72b"
      },
      "cell_type": "code",
      "source": "# check unique number of object columns\ncat_list = [\"Pclass\",\"Name\",\"Sex\",\"Ticket\",\"Cabin\",\"Embarked\"]\ntrain_df[cat_list].nunique()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "17958e516624fa46da0882c1d4dc1dde8f1ac285"
      },
      "cell_type": "markdown",
      "source": " There are 891 rows in train data. \"Name\" has 891 unique value and \"Ticket\" has 681 unique value. We could consider drop them since they are so various. "
    },
    {
      "metadata": {
        "_uuid": "ff03d5488a87eff5134984419adc05af6bc0c22b"
      },
      "cell_type": "markdown",
      "source": "I think the following is Feature Engineering. If I was wrong, please tell me."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "22b0d33e698a11e0e9b7550e9535471412189e46"
      },
      "cell_type": "code",
      "source": "# drop columns\ndrop_cols = [\"Name\",\"Ticket\"]\ntrain_df.drop(drop_cols, axis=1, inplace=True)\ntest_df.drop(drop_cols, axis=1, inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bdadeadc8333e0176af7acbaf8378a4aa41773e6"
      },
      "cell_type": "code",
      "source": "# extract traget \ntrain_y = train_df.Survived",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "95b98403ed3d22757e8bb73d03b5c72b0ba04b6c"
      },
      "cell_type": "code",
      "source": "# extract ID of test for submission file\ntest_ID = test_df.PassengerId",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "82443ea47d82a5c197414c3a3e3b8ba48fbf7c00"
      },
      "cell_type": "code",
      "source": "# drop PassengerId\ntrain_X = train_df.drop([\"PassengerId\"], axis=1)\ntest_X = test_df.drop([\"PassengerId\"], axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "228422f03f204e59c6f5e2251b25dd63c21853d0"
      },
      "cell_type": "code",
      "source": "# extract features for training\ntrain_X = train_X.drop([\"Survived\"], axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5bbe88aa8ce343d06f635a4fd0878e7518f8f6fb"
      },
      "cell_type": "markdown",
      "source": "This part is dealing with missing values and encoding categorical columns in order to be used in XGBoost model."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ac22665b36902c35546ace4219450e4cb0ffaeab"
      },
      "cell_type": "code",
      "source": "# check columns with NaN\ncols_with_missing = [col for col in train_X.columns \n                                 if train_X[col].isnull().any()]\ncols_with_missing",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fb799d3bd35a0ed3aa2fda2fd6076d1657f5ec9e"
      },
      "cell_type": "markdown",
      "source": "Firstly, select which columns are numeric and which are categorical and then handling with them seperately."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "260edc6a9eb4e9cef8ecbba535b71e440a2b10fc"
      },
      "cell_type": "code",
      "source": "# two lists contain numerical columns' name and categorical columns' name\nnum_cols = [\"Age\",\"SibSp\",\"Parch\",\"Fare\"]\ncat_cols = [\"Sex\",\"Cabin\",\"Embarked\",\"Pclass\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ba9e025cc582e5651e194af2552c9ab29798270f"
      },
      "cell_type": "code",
      "source": "# handling missing value in num_cols using impute\nnum_imputer = SimpleImputer()\ntrain_X[num_cols] = num_imputer.fit_transform(train_X[num_cols])\ntest_X[num_cols] = num_imputer.fit_transform(test_X[num_cols])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0226a4d5ad7e916ea66f1464066636f3dfce5f8c"
      },
      "cell_type": "code",
      "source": "# handling categorical columns using number label\nfor col in cat_cols:\n    cat = LabelEncoder()\n    cat.fit(list(train_X[col].values.astype('str')) + list(test_X[col].values.astype('str')))\n    train_X[col] = cat.transform(list(train_X[col].values.astype('str')))\n    test_X[col] = cat.transform(list(test_X[col].values.astype('str')))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cbb60e508d895662fe67491dc947947174f71aef"
      },
      "cell_type": "markdown",
      "source": "After feature engineering, handling missing values and converting categorical values, I will use XGBoost algorithm to build model and predict for test dataset."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c77c56e4ba3a97bc3ce3e01a6f232b2c75b3add4"
      },
      "cell_type": "code",
      "source": "# create XGBClassifier instance\nclassifier = XGBClassifier()\n# set hypermeters and the below values are trained in order to run fast\ngrid_param = {\"learning_rate\" : [0.06],\n              'n_estimators': [300],\n              'colsample_bytree': [0.7],\n              'reg_alpha': [0.04]\n              }\n\ngd_sr = GridSearchCV(estimator=classifier,  \n                     param_grid=grid_param,\n                     scoring='accuracy',\n                     cv=10,\n                     n_jobs=-1,\n                    verbose=1)\ngd_sr.fit(train_X, train_y) ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b20b62f1f817ca73128b8efcacf88b6a602819e8"
      },
      "cell_type": "code",
      "source": "# print the best hyparameters, but for my case, the best parameters are shown as above\n# I used this to find the best hyperparameters from lots of hyparameters combination\nbest_parameters = gd_sr.best_params_  \nprint(best_parameters)  ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3715a0b3973dd6d4cd843f6554ae6c2711fecf64"
      },
      "cell_type": "code",
      "source": "train_pred = gd_sr.predict(train_X)\npred_train = [round(value) for value in train_pred]\n# evaluate predictions\nacc_train = accuracy_score(train_y, pred_train)\nprint(\"Train_Accuracy: %.2f%%\" % (acc_train * 100.0))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b34e30fe56aaba1e1ca40adf44c125175523a8ae"
      },
      "cell_type": "code",
      "source": "# predict test dataset\npredictions = gd_sr.predict(test_X)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "da3d3790c2ba3247f5717cae09f87dad14306ca3"
      },
      "cell_type": "code",
      "source": "# satisfy submission format\nmy_submission = pd.DataFrame({'PassengerId':test_ID,'Survived':predictions})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9f3b38f4e297e240c5b23b1ebfa20a4b57359298"
      },
      "cell_type": "code",
      "source": "# export as csv file\nmy_submission.to_csv(\"sub.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "891cebd2d83a66611d59871bea279b108e605d93"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}