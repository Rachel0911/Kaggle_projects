{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook analyzes description column in winemag-data_first150k.csv. \n",
    "The description contains text and I just learn some techniques about NLP. Try to use them here. This is kind of sentiment analysis. I add a new column called tasety based on points column. If the points is greater than or equal 88, the tasety is 1, otherwise, tasety is 0. 88 is chosen since it is the median of the whole data in points column. The goal of this notebook is to find the high frequent positive description words and negative description words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "import string\n",
    "\n",
    "# import sklearn libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# import nltk library to do text analysis\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select 5000 sample from positive data and select 5000 sample from negative data. Since the raw data is too large, the notebook will die."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_tasety = pd.read_csv(\"/Users/rwang/PycharmProjects/Kaggle_projects/Wine data analysis/description_tasety.csv\", index_col=0)\n",
    "description_tasety_pos = description_tasety[description_tasety.tasety==1].sample(5000, random_state=0)\n",
    "description_tasety_neg = description_tasety[description_tasety.tasety==0].sample(5000, random_state=0)\n",
    "description_tasety = description_tasety_pos.append(description_tasety_neg).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    9695\n",
       "True      305\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicated rows. Many rows are duplicated. and remove the duplicated rows.\n",
    "description_tasety.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicateRows = description_tasety[description_tasety.duplicated()]\n",
    "description_tasety.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    4849\n",
       "0.0    4846\n",
       "Name: tasety, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check positive and negative rows number\n",
    "description_tasety.tasety.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is beginning to preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all string in description into lower case\n",
    "description_tasety.loc[:, 'description'] = description_tasety['description'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuations in description\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_tasety.loc[:, 'description'] = description_tasety['description'].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove number in description\n",
    "description_tasety.loc[:, 'description'] = description_tasety['description'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert description into word token. Each instance in description is becoming list of words without punctuations \n",
    "# and number\n",
    "description_tasety['description_token'] = description_tasety['description'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words in text field\n",
    "stop = stopwords.words('english')\n",
    "description_tasety['description_token'] = description_tasety['description_token'].apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of words to string which will be used for next steps\n",
    "description_tasety['description_token']=description_tasety['description_token'].apply(lambda x: \" \".join(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take bag of 1-gram with tfidf\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 1))\n",
    "features = tfidf.fit_transform(description_tasety['description_token'])\n",
    "X = pd.DataFrame(features.todense(),\n",
    "            columns=tfidf.get_feature_names())\n",
    "target = description_tasety['tasety']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End preprocess text. Use logisticRegression to creat the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = LogisticRegression(C=1)\n",
    "final_model.fit(X, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top positive word:  ('long', 4.857741021932491)\n",
      "top positive word:  ('years', 4.519974764546312)\n",
      "top positive word:  ('elegant', 3.423864927559103)\n",
      "top positive word:  ('lovely', 3.2824082492823266)\n",
      "top positive word:  ('pure', 3.1929487910152043)\n",
      "------------------------------------------------------------\n",
      "top negative word:  ('simple', -4.828173651004282)\n",
      "top negative word:  ('easy', -3.1711054901580664)\n",
      "top negative word:  ('flavors', -2.957474059668208)\n",
      "top negative word:  ('everyday', -2.7993960121546495)\n",
      "top negative word:  ('soft', -2.7436186687785096)\n"
     ]
    }
   ],
   "source": [
    "# find the top positive words and negative words\n",
    "feature_to_coef = {word: coef for word, coef in zip(tfidf.get_feature_names(), final_model.coef_[0])}\n",
    "\n",
    "positives = sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)\n",
    "for best_positive in positives[:5]:\n",
    "    print (\"top positive word: \", best_positive)\n",
    "\n",
    "print('-'*60)\n",
    "negatives = sorted(feature_to_coef.items(), key=lambda x: x[1])\n",
    "    \n",
    "for best_negative in negatives[:5]:\n",
    "    print (\"top negative word: \", best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusion:\n",
    "The top positive words are 'long', 'years', 'elegant', 'lovely', and 'pure'. 'long', and 'years' are difficult to explan. Since I just use 1-gram tfidf, it just gives the single word. We could guess the phrase according to them. Like 'long sunshine', 'many years'. Now, they are consistent with our opinion when we comment the good wines. <br>\n",
    "The top negative words are 'simple', 'easy', 'flavors', 'everyday', 'soft'. Also, guess the phrase, 'bad flavors', 'it's soft'. They are common words what we will say when we feel the wines are not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
